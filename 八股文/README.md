#### JAVA

##### JVM

> 组成：类加载器、运行期数据区、执行引擎

> 运行期数据组成：程序计数器、栈、堆、方法区
>
> 程序计数器：表示某个线程执行代码位置
>
> 栈：存放线程执行的方法(指向运行时常量池的引用)，和方法内的局部变量
>
> 堆：存放对象
>
> 方法区：JVM加载class信息、静态变量、常量

##### JVM垃圾回收

###### 垃圾对象标记算法

> 引用计数法：对象有引用+1，引用为0的可以回收
>
> 可达性分析：从GCROOT出发，对引用的对象进行标记
>
> GCROOT：线程栈中的变量、方法区静态属性、方法区常量、JNI引用对象

###### 回收算法

> 清理1、标记清除算法：标记、清除(不会真正清理，只是记录在可用空间表里)
>
> 压缩2、标记整理：标记、整理(移动所有存活对象)，按内存地址依次排序，最后将末端后的内存回收
>
> 复制：将内存分为对象和空闲2部分，对象部分用完后吧存货的复制到空闲的区域

###### 垃圾收集器

新生代：Serial(串行)；ParNew、Parallel Scanvenge 都是复制算法

老年代：Serial(标记整理)、Parallel(标记整理)、CMS(标记清除)

G1:适用于新生代和老年代(复制+标记整理)：分区：新生代(Eden、Surivivor)、老年代、大对象(连续的块)
G1的回收：YGC、MixedGC(Y、Old(根据设置回收时间选择回收的多少)、大对象、FullGC

G1也是2阶段标记，然后使用复制来进行回收。回收根据设置的stw时间决定回收部分region

https://zhuanlan.zhihu.com/p/83804324

CMS：是为了影响用户时间最短，回收的某个阶段可以用户线程和回收线程并行

##### 锁

> 1、乐观锁VS悲观锁：悲观锁是认为会有其他线程访问，所以需要加锁(synchronized、lock);乐观锁，不认为有其他线程访问，CAS(其实就是无锁)
>
> 2、自旋锁：线程不阻塞，避免操作系统切换cpu。CAS，一直while循环自选，默认10。自适应自旋，根据前一次在锁上的自旋时间决定
>
> 3、公平锁、非公平锁：公平锁根据线程申请锁的顺序获取锁。非公平锁是释放锁时，如果有线程正好获取锁，直接获取成功。都不需要唤醒等待的线程ReentrantLock,底层基于AQS(标识加锁值(锁了多少次)、当前线程id、排队队列)
>
> 4、无锁、偏向锁、轻量级锁、重量级锁：是针对synchronized。存在对象头
>
> 5、可重入、非可重入锁：ReentrantLock、synchronized是可重入锁
>
> 6、独享锁、共享锁：也是基于AQS，有一个写锁和读锁。拆分state标识2个锁的锁个数。有读锁时不能申请写锁，有写锁时读锁阻塞。

锁消除：编译期间锁优化。认为没有加锁的必要（比如，锁加到了局部变量上）

##### 线程池

参数：核心线程数、最大线程数、keepalivetime、队列、拒绝策略

LinkedBlockingQueue:有界队列

SynchronousQueue：没有队列的queue。生产时没有消费的，直接自旋然后sleep。消费类似

##### 优秀java数据结构

###### LongAdder

java8解决CAS大量线程空循环

1、线程不多时使用base变量来累加

2、线程竞争激励后使用cell数组(初始2，只要有竞争同一个cell会扩容，直到大于等于cpu个数)

说明：a、这样保证了只有一个线程来操作同一个cell。b、线程和数据对应关系是根据线程的一个变量threadLocalRandomProbe&(size-1)

#### Spring

##### Spring Boot 是如何进行自动装配的

1、@SpringBootApplication对应的@EnableAutoConfiguration，导入AutoConfigurationImportSelector.class

2、加载MEAT-INF/spring.factories下的文件

3、文件下都是Config类，使用@Conditional注解，根据是否引入class、是否有对应配置等再加载bean

##### Spring三级缓存

1、初始化、装配完的bean

2、初始化，但是没有装配bean的早起bean

3、bean工厂。bean可能会有AOP的情况，所以使用工厂来处理

####  数据库

##### Mysql：单机1000QPS

核心原理：

1、mysql数据结构

> 1、采用B+树结构：非叶子结点不存储data，只存储指针。叶子结点存储data；每个叶子结点有指向相邻叶子结点的指针

2、索引

> 1、主键索引、非主键索引。主键索引保存数据，非主键索引保存主键值
>
> 2、回表：就是使用非主键索引查询到主键后，再去主键索引上查询数据
>
> 3、查询优化：覆盖索引(查询的值再非主键索引上，即不需要回表)；最左索引(索引是排序好的，可以使用like'xx%')；索引下推，可以对索引上的字段进行过滤(需要保证是=值查询)，减少回表次数

3、事务

> 读未提交：事务没提交变更也能被看到(别人改的数据，没提交事务我也能看到)
>
> 读提交：事务提交后的变更才能被看到(别人改的数据事务提交后我才能看到)
>
> 可重复读：事务执行过程中看到的数据和事务开启时数据一直(mysql使用MVCC实现)
>
> 串行化：读写都加锁

4、MVCC 多版本并发控制

> 事务隔离的一种实现。用来实现提交读和可重复读
>
> 原理：数据库有隐藏的2列(创建版本号、删除版本号)。每个事务会创建read-view，有对应的undo log（回滚日志）。可重复读事务获取值时，先获取当前值，再根据read-view和事务id回滚对应的事务

5、锁

> 表锁：
>
> 行锁：原理是在索引上加锁(主键索引直接加，非主键索引加非索引和对应的主键索引)
>
> next-key lock(间隙锁+行锁)：在update、delete时在mysql索引扫描过的记录，和相邻的键值(在可重复读级别解决幻读问题)。本质是锁住B+树的左右索引指针，保证前后不能插入数据

共享锁：lock in share mode

排它锁：update、delete、insert、for update

意向锁：申请行锁时，先申请意向锁。表示我表中有一行在使用锁。当表锁来时，判断有意向锁，就等待

6、日志

> binlog：mysql的server层。归档日志。可以用来恢复数据。记录的是具体sql
>
> redo log：InnoDB的日志。数据更新时先写日志，等周期或者日志满再刷到磁盘，提供了crash-safe能力。即WAL(write-ahead loggin,预写日志)。其实是为了Buffer Pool问题引入的(InnoDB为了提升效率，把部分数据也映射，作为数据库的缓冲，会先写Buffer Pool，定期刷新到磁盘)
>
> undo Log：回滚日志。记录事务的回滚日志。是事务的原子性和隔离性的实现基础



常见问题：

1、InnoDB数据的一致性

根据binlog 和redolog的2阶段提交：prepare、写binlog、commit。宕机后根据2个日志的状态可以进行对应的回滚

2、主从数据不一致

> 1、强制读主
>
> 2、缓存需要读取主库的数据key，并根据主从同步时延设置超时时间

3、数据库和缓存的一致性

> 1、先更新数据库，后删除缓存
>
> 2、主从模式，缓存不一致：可以使用cacel订阅从库的binlog来删除缓存

4、索引失效场景

> 1、不使用不等于(!= <>)
>
> 2、不进行null判断(is null,is not null)
>
> 3、in、not in
>
> 4、like 没有最左前缀
>
> 5、where字段使用函数操作
>
> 6、使用or连接了没有索引的字段

5、B+树优于B树的原因

> 1、可以范围查找(确定最大、最小值后，利用叶子节点的链表可以获取结果)
>
> 2、叶子节点紧密适合磁盘存储，非叶子节点适合内存存储
>
> 3、磁盘预读，非叶子节点可以加载更多索引到内存

##### Redis ：单机10wQPS

核心原理

1、redis的单线程模型

> 1、使用文件事件处理器(包括：多个套接字，IO多路复用、文件事件分派器、事件处理器)，因为文件事件分派器是单线程的，所以redis是单线程的
>
> 2、redis6.0使用多线程：请求接收和解析，以及处理后通过网络返回是使用多线程。命令请求的数据读写还是单线程

2、redis过期删除策略

>a、redisDb数据中，存在一个expires的map，用于存放设置过期时间的key
>
>b、过期策略：惰性删除（访问时先判断是否过期，过期则删除）;redis周期获取一定过期的随机key进行检查，删除
>
>c、从库不会删除过期key，主库删除时同步给从库删除命令。过期期间从库读取(3.2前返回值，3.2从库判断是否过期，过期不返回，但是不删除)

3、redis持久化

> 1、2种持久化方式：RDB(快照-fork子进程把全量数据保存到文件);AOF(记录写命令，追加到AOF末尾。时间长后需要重写--主线程fork子进程，内存也拷贝，读取内存成命令写AOF，过程中的命令会写2份(原来的AOF、重新的AOF))
>
> 2、RDB适合做冷备,恢复时间快

4、redis内存淘汰机制

> 默认不淘汰，内存不足时报错
>
> volatile前缀是对于设置过期时间的key
>
> allkeys对于所有key
>
> 常用：xxx-LRU(lateset recently used)最近使用；LFU(latest Frequently used)：最不常用；随机；ttl(即将过期)

5、redis分布式部署方式

> 3种方式：简单主从模式(master宕机手动切换)，保证高可用的redis哨兵模式(sentinel)--主从;扩展存储的cluster模式，使用cluster分片存储，每个分片分配多个hash槽来存储key--去中心
>
> 主从同步方式：
>
> a、从库启动时，主库通过bgsave生成RDB同步给从库，同时把repl_backlog_buffer(一个环形缓冲区)数据给从库
>
> b、从库同步完文件后，通过replication_buffer中的offset同步repl_backlog_buffer中的内容
>
> c、建立长链接开始常规的命令复制
>
> d、长链接断开的话，根据replication_buffer中的offset同步repl_backlog_buffer



常见问题：

1、缓存雪崩、击穿、穿透

> 雪崩：大量的key设置了相同的过期时间，缓存失效，导致大量请求顺时DB压力增大--过期时间加上随机值；设置熔断防止db挂掉
>
> 击穿：一个热点key，失效后对db造成压力--查询db时设置互斥锁(setnx)
>
> 穿透：访问不存在的key，请求会穿透到DB，对DB造成压力--接口层添加校验(过滤不合理的参数)；空值写进缓存添加较短的过期时间；布隆过滤器，不存在的key直接过滤

2、redis分布式锁

三要素：安全(互斥)，死锁释放，故障容错

> 互斥：使用原子的操作设置
>
> 死锁释放：设置超时时间、自动续期；删除时先判断再删除
>
> 故障容错：RedLock方案：添加锁需要n/2+1个节点设置成功。删除锁发送给所有节点

3、分布式锁遇到主从同步

redis是AP不是CP，所以会存在问题

> RedLock方案：使用多个master记录锁，删除锁给所有节点发送
>
> 如果对锁特别敏感建议使用ZK，保证强一致性

4、redis的事件处理器

> 连接应答处理器、命令请求处理器、命令回复处理器、主从连接处理器、PING/PONG处理器

#### 中间件

##### Zookeeper

一个分布式协调服务框架。主要解决分布式系统中各种通用一致性问题

##### 架构

提供了分布式存储系统：树形存储结构，节点(ZNode)。

临时节点：1、集群与客户端的心跳，判断是否删除临时节点。2、Watcher机制，节点或者子节点状态变化，通知监听的客户端

自动选举

#### Kafka

##### 整体架构

1、kafka使用发布订阅模型。producer消息使用push方式给到集群中，consumer使用pull的方式从集群中拉取消息

2、流程：producers->topic->topic_partition(leader)->consumers

ZK在其中的作用：存储集群的meta等信息。

如：/brokers/ids/：Broker信息；/brokers/topics/：多个主题；/brokers/topicA/partitions/：主题A下的分区(创建topic的时候指定了多少个)

/brokers/topicA/partitions/0/state：临时节点，由leader broker创建。保存了leader和所有同步leader的follower的BrokerID

3、每个Broker维护了一份和ZK中一样的元数据缓存，客户端获取是去Broker获取关心的元数据，保证生产和消费

##### 存储机制

Topic->多个Partition->多个segment(.index和.log)

###### 查找对应offset的消息时

offset维护在broker的一个内部主题_consumer_offsets

先根据offset二分查找找到segment，根据segment的.index二分查找找到对应的索引或者小于offset最大的那个索引(由于是稀疏索引，可能没有指定offset)，再顺序扫描找到对应的message

##### 分区策略

生产者把消息发送到哪个分区：

1、可以指定分区

2、基于消息key的分配。即消息key的hash来计算分区

3、轮询策略

消费者消费哪个分区：

1、Range分配：按topic。分区/消费线程。除不尽，前面几个消费者多消费一个分区。消费者多会出现不消费的情况。缺点：根据topic来分，当有多个topic时可能第一个一直多

2、RoundRobinAssignor 轮询分区：把consumer组的所有topic和consumer列出，进行轮询分配。缺点：当消费者订阅的topic不同时，轮询可能会，比如一个消费者订阅了所有的topic，他分配的可能会多

3、Sticky策略：原则为，a、分区的分配尽可能均匀。b、分配的分区尽可能与上次分配一致

##### Kafka高性能IO

1、批处理：send消息是批量发送，批量存储、批量消费

2、保存磁盘是顺序读写

3、利用操作系统的PageCache来缓存数据(其实是kafka的特性，生产消息后，立马会有消费)

4、零拷贝：文件->内核缓冲区->内存->socket。内存这一步是多余的，因为不需要对消息进行处理，所以可以使用零拷贝技术(sendfile)

##### 高可用

副本机制，或者Leader Follower机制。Follower采用pull的模式获取消息

##### 消息不丢失

kafka有3中ack机制：0：不等待应答；1等待leader应答；-1等待leader同步给follower后应答(可能会重复)

##### 分布式事务

加入了事务协调器。

1、producer开启事务时去协调器获取事务id

2、发送消息前，把Topic、Partition发送给协调器

3、发送消息到broker(消息是未提交的消息，消费者读取时会缓存起来，等待commit消息)。同时发送消息的offset给协调器

4、提交事务

5、协调者发送事务结束消息给每个分区



常见问题：

##### 发送有序消息

1、指定partitionKey，同类消息写入同一个partition中

2、利用Producer幂等性。添加PID和Sequence Number(单调递增)。Broker只接收大一的消息，大的消息拒绝，那Producer会重试。小的消息直接丢失(说明有重复)

3、消费端，需要判断相同的key当到同一个队列中去处理

#### 扩展

##### 布隆过滤器

一个很长的二进制向量和多个hash函数。key哈希后对应的向量位置设为1，当判断key是否存在是，hash后看对应位置是否都为2。

返回结果：一定不存在、可能存在(因为可能会误判)

##### master/slave和leader/follower

master/slave即为主从，一般用于数据库场景。master写，slave读

leader/follower其实是为高可用准备。follower只承担副本的作用，当leader宕机后在多个follower选举出leader

##### 大数据

HDFS：分布式文件存储。由NameNode和DataNode组成

###### Presto

基于内存计算的引擎

主从式。主节点coordinator负责Sql优化和执行计划生成。同时管理整个集群的内存管理




##### 秒杀系统

核心问题是高并发。处理方案：流量控制、资源隔离(不影响其他业务，可以把秒杀的数据库、缓存单独申请资源)

业务方面：分时段秒杀、品类分天优惠等等

1、客户端页面CDN缓存

2、网关：黑名单、ip刷单问题

3、流量控制(sentinel 和 spring cloud gateway)

4、服务端处理并发(MQ来排队,如果库存没了，直接返回失败)

5、MQ消费，处理商品扣减->数据库



